{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1424e9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for news about: 'china' using NewsAPI.org\n",
      "Successfully saved 18 articles to newsapi_china_20250621_150000.json\n"
     ]
    }
   ],
   "source": [
    "# scraper_newsapi.py (JSON Output Version)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json  # Import the json library instead of csv\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Note: It's better to use the API key from your .env file\n",
    "# API_KEY = os.getenv(\"NEWSAPI_KEY\") \n",
    "# However, I will use the one you provided in the script for this example.\n",
    "API_KEY = \"68f0b4a61fe644c7b90bcc655c84f826\"\n",
    "BASE_URL = \"https://newsapi.org/v2\"\n",
    "\n",
    "def fetch_news_by_query(query):\n",
    "    \"\"\"Fetches news based on a search query using the /everything endpoint.\"\"\"\n",
    "    endpoint = \"/everything\"\n",
    "    \n",
    "    headers = {\n",
    "        'X-Api-Key': API_KEY # Use the API_KEY variable\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        'q': query,\n",
    "        'language': 'en',\n",
    "        'sortBy': 'publishedAt',\n",
    "        'pageSize': 20,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(BASE_URL + endpoint, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        if data.get('status') != 'ok':\n",
    "            print(f\"API Error: {data.get('message')}\")\n",
    "            return []\n",
    "            \n",
    "        # The 'articles' key already contains a list of dictionaries, which is perfect for JSON\n",
    "        return data.get('articles', [])\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for query '{query}': {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- REPLACED FUNCTION ---\n",
    "# The save_articles_to_csv function is replaced by save_articles_to_json\n",
    "def save_articles_to_json(articles, query):\n",
    "    \"\"\"Saves a list of NewsAPI articles to a JSON file.\"\"\"\n",
    "    if not articles:\n",
    "        print(\"No articles to save.\")\n",
    "        return\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    # Use the .json file extension\n",
    "    filename = f\"newsapi_{query.replace(' ', '_')}_{timestamp}.json\"\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as jsonfile:\n",
    "            # Use json.dump() to write the Python list to a JSON file\n",
    "            # 'indent=4' makes the file human-readable\n",
    "            # 'ensure_ascii=False' allows for special characters (like accents) to be saved correctly\n",
    "            json.dump(articles, jsonfile, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        print(f\"Successfully saved {len(articles)} articles to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to JSON file: {e}\")\n",
    "\n",
    "# Main execution block\n",
    "if __name__ == \"__main__\":\n",
    "    search_query = input(\"Enter a search query for news: \").strip()\n",
    "    \n",
    "    if not search_query:\n",
    "        print(\"Search query cannot be empty.\")\n",
    "    else:\n",
    "        print(f\"Searching for news about: '{search_query}' using NewsAPI.org\")\n",
    "        \n",
    "        # 1. Fetch the news\n",
    "        found_articles = fetch_news_by_query(search_query)\n",
    "        \n",
    "        # 2. Save the news to a JSON file (updated call)\n",
    "        if found_articles:\n",
    "            save_articles_to_json(found_articles, search_query)\n",
    "        else:\n",
    "            print(\"Could not find any articles for the given query.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba3043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = f\"\"\"\n",
    "You are an expert financial analyst AI. Your task is to analyze the provided list of news articles to generate investment recommendations.\n",
    "\n",
    "Follow these steps precisely:\n",
    "1.  Read through the entire JSON array of articles provided below.\n",
    "2.  For each article, identify the primary companies mentioned and the sentiment of the news (Positive, Negative, or Neutral) regarding each company's business prospects.\n",
    "3.  Synthesize the findings for each company across all articles they appear in.\n",
    "4.  Based on the overall sentiment and the potential business impact described, select the 5 most promising stocks to invest in. For each, provide a stock ticker if it's a well-known public company.\n",
    "5.  Provide a concise 'reasoning' for each recommendation, directly referencing the news content.\n",
    "6.  Identify at least two 'stocksToAvoid' based on negative news and provide the reasoning.\n",
    "7.  Your final output must be a single, valid JSON object and nothing else. Do not include any text or explanations before or after the JSON block.\n",
    "\n",
    "Here is the required JSON output structure:\n",
    "\n",
    "{{\n",
    "  \"investmentAnalysis\": {{\n",
    "    \"stocksToInvest\": [\n",
    "      {{\n",
    "        \"companyName\": \"Example Company A\",\n",
    "        \"stockTicker\": \"EXA\",\n",
    "        \"reasoning\": \"A brief, data-driven reason based on the provided articles.\"\n",
    "      }}\n",
    "    ],\n",
    "    \"stocksToAvoid\": [\n",
    "      {{\n",
    "        \"companyName\": \"Example Company B\",\n",
    "        \"stockTicker\": \"EXB\",\n",
    "        \"reasoning\": \"A brief, data-driven reason based on the provided articles.\"\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "}}\n",
    "\n",
    "---\n",
    "Here are the news articles:\n",
    "\n",
    "{found_articles}\n",
    "\"\"\"\n",
    "\n",
    "# # 4. --- Prepare the Request Body ---\n",
    "# # The body must be a JSON object that follows the Gemini API's structure.\n",
    "# # We also specify that the output must be JSON.\n",
    "# request_body = {\n",
    "#   \"contents\": [{\n",
    "#     \"parts\": [{\n",
    "#       \"text\": prompt_template\n",
    "#     }]\n",
    "#   }],\n",
    "#   \"generationConfig\": {\n",
    "#     \"responseMimeType\": \"application/json\"\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6233ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"investmentAnalysis\": {\n",
      "    \"stocksToInvest\": [\n",
      "      {\n",
      "        \"companyName\": \"Microsoft\",\n",
      "        \"stockTicker\": \"MSFT\",\n",
      "        \"reasoning\": \"ChatGPT, a major AI product with Microsoft investment, leads global AI traffic referrals, indicating strong market position and growth in the critical AI sector.\"\n",
      "      },\n",
      "      {\n",
      "        \"companyName\": \"Apple\",\n",
      "        \"stockTicker\": \"AAPL\",\n",
      "        \"reasoning\": \"Apple benefits from supply chain diversification as its primary assembler, Foxconn, expands iPhone casing manufacturing in India, enhancing resilience and reducing reliance on a single region.\"\n",
      "      },\n",
      "      {\n",
      "        \"companyName\": \"Foxconn (Hon Hai Precision Industry)\",\n",
      "        \"stockTicker\": \"HNHPF\",\n",
      "        \"reasoning\": \"Foxconn is directly expanding iPhone casing manufacturing in India, signaling strategic supply chain diversification and strengthening its position as a key global electronics manufacturer.\"\n",
      "      },\n",
      "      {\n",
      "        \"companyName\": \"Baidu\",\n",
      "        \"stockTicker\": \"BIDU\",\n",
      "        \"reasoning\": \"As a leading Chinese AI company, Baidu is poised to benefit from China's strong domestic AI ecosystem, exemplified by DeepSeek's dominance within China due to local regulations and language tools, fostering local AI superpowers.\"\n",
      "      },\n",
      "      {\n",
      "        \"companyName\": \"Tencent Holdings\",\n",
      "        \"stockTicker\": \"TCEHY\",\n",
      "        \"reasoning\": \"Tencent, a major Chinese tech conglomerate, has significant investments in AI and stands to benefit from the general trend of 'domestic AI superpowers' thriving in China, as highlighted by local AI firms leveraging unique market conditions.\"\n",
      "      }\n",
      "    ],\n",
      "    \"stocksToAvoid\": [\n",
      "      {\n",
      "        \"companyName\": \"Google (Alphabet)\",\n",
      "        \"stockTicker\": \"GOOGL\",\n",
      "        \"reasoning\": \"Google's Gemini AI is reported to be 'far behind' ChatGPT in global AI usage, indicating a significant competitive disadvantage in the rapidly evolving and crucial AI search market.\"\n",
      "      },\n",
      "      {\n",
      "        \"companyName\": \"US Biotech Industry (Representative: Moderna)\",\n",
      "        \"stockTicker\": \"MRNA\",\n",
      "        \"reasoning\": \"The US biotech industry is facing an increasing threat, with China noted as having 'the most immediate opportunity to overtake' the United States in biotechnology, posing risks to established US players like Moderna.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyDCLQSiHQfXwtbpQ8Uf6AH6DZe6Zz6nOAs\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=prompt_template\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252cbbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BTCUSD': 0, 'ETHUSD': 1}\n",
      "Sold all 1 shares of ETHUSD\n",
      "Bought 1 shares of AAPL at $201.03 each, total $201.03\n",
      "Not enough funds to buy any shares of MSFT\n",
      "Not enough funds to buy any shares of TSLA\n",
      "Not enough funds to buy any shares of NFLX\n"
     ]
    }
   ],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "# Alpaca API credentials (replace with your own)\n",
    "API_KEY = 'PKCGJW9FKXGKCS00B77K'\n",
    "API_SECRET = 'z7comnhSg9w1OQ7h7YX2PxETCXpq1DZSqHDGOSAI'\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'\n",
    "\n",
    "# Example input\n",
    "response = ['AAPL', 'MSFT', 'TSLA', 'NFLX']  # Most confident to least\n",
    "total_investment = 1000  # User input\n",
    "companies_to_avoid = ['GOOGL', 'ETHUSD']  # Example companies to avoid\n",
    "\n",
    "# Distribute funds: highest confidence gets most, lowest gets least\n",
    "n = len(response)\n",
    "weights = [n - i for i in range(n)]  # e.g., [4, 3, 2, 1]\n",
    "weight_sum = sum(weights)\n",
    "allocations = [total_investment * (w / weight_sum) for w in weights]\n",
    "\n",
    "# Connect to Alpaca\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, BASE_URL, api_version='v2')\n",
    "\n",
    "# Sell all shares of companies to avoid if owned\n",
    "positions = {pos.symbol: int(float(pos.qty)) for pos in api.list_positions()}\n",
    "print(positions)\n",
    "for symbol in companies_to_avoid:\n",
    "    if symbol in positions and positions[symbol] > 0:\n",
    "        api.submit_order(\n",
    "            symbol=symbol,\n",
    "            qty=positions[symbol],\n",
    "            side='sell',\n",
    "            type='market',\n",
    "            time_in_force='gtc'\n",
    "        )\n",
    "        print(f\"Sold all {positions[symbol]} shares of {symbol}\")\n",
    "\n",
    "# Buy shares based on confidence\n",
    "for symbol, amount in zip(response, allocations):\n",
    "    # Get latest price\n",
    "    barset = api.get_latest_trade(symbol)\n",
    "    price = barset.price\n",
    "\n",
    "    qty = int(amount // price)\n",
    "    if qty > 0:\n",
    "        api.submit_order(\n",
    "            symbol=symbol,\n",
    "            qty=qty,\n",
    "            side='buy',\n",
    "            type='market',\n",
    "            time_in_force='gtc'\n",
    "        )\n",
    "        print(f\"Bought {qty} shares of {symbol} at ${price:.2f} each, total ${qty*price:.2f}\")\n",
    "    else:\n",
    "        print(f\"Not enough funds to buy any shares of {symbol}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
